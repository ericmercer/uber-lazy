\section{Introduction}

In recent years symbolic execution has provided the basis for various 
software testing and analysis techniques. Symbolic execution
systematically explores the program execution space using
symbolic input values, and for each explored path, computes
constraints on the symbolic inputs to create a \emph{ path condition}.
The set of path conditions computed by
symbolic execution characterize the observed program execution
behaviours and have been used as an enabling technology for various
applications, e.g., regression
analysis~\cite{backes:2012,Godefroid:SAS11,Person:FSE08,person:pldi2011,Ramos:2011,Yang:ISSTA12},
data structure repair~\cite{KhurshidETAL05RepairingStructurally},
dynamic discovery of
invariants~\cite{CsallnerETAL08DySy,Zhang:ISSTA14}, and
debugging~\cite{Ma:2011}.

Initial work on symbolic execution largely focused on checking 
properties of programs with primitive types~\cite{clarke76TSE,King:76}.
%, e.g., integers and booleans 
%Despite recent advances
%in constraint solving technologies, improvements in
%raw computing power, and advances in reduction
%and abstraction techniques~\cite{AnandETAL2009AbsSymExe,Godefroid:POPL07}
%symbolic execution of programs of modest size containing only
%primitive types, remains challenging
%because of the large number of execution paths generated
%during symbolic analysis. 
With the advent of object-oriented languages,
% e.g., Java and C$++$, 
recent work has generalized the core ideas of symbolic execution to enable 
analysis of programs containing complex data structures with unbounded 
domains, i.e., data stored on the heap~\cite{Kiasan06,Kiasan07,GSE03}.  
These \emph{Generalized Symbolic Execution} (GSE) techniques construct the 
heap in a lazy manner, deferring
materialization of objects on the concrete heap until they are needed
for the analysis to proceed. The materilization 
%accounts for various heap configurations, 
creates additional non-deterministic choice points in the symbolic
execution tree by representing the feasible heap configurations as (i)
null, (ii) an instance of a new reference of a compatible class, and (iii)
an alias to a previously initialized symbolic reference.  Symbolic
execution then follows concrete program semantics for materialized heap
locations. Although this approach enables the analysis of heap
manipulating programs, a large number of feasible concrete heap
configurations are created leading to state space explosion.

%  resulting in a large number of feasible concrete heap
%configurations, and as a result, a large number of points of
%non-determinism to be analyzed.
%, further exacerbating the state space
%explosion problem.

The goal of this work is to mitigate the state space explosion problem
in GSE by grouping multiple heaps together and only partitioning the
heaps at points of divergence in the control flow graph. Our
inspiration is found in the domain of static analysis that uses sets
of constraints over heap locations to encode multiple heaps in a
single representation. These sets, sometimes known as \emph{value sets} or
\emph{value summaries}, allow multiple heaps to be represented simultaneously
with a higher degree of precision than afforded by traditional
techniques for shape analysis.

Unfortunately, value sets often do not support aliasing and require a
recursive definition of objects~\cite{..}. Also, heap updates often
require that the path constraint be rewritten to reflect the update,
and the constraints in the value set may also need to be rewritten with the
addition of auxiliary variables. These non-local operations make it
difficult to use value sets in symbolic execution. As is
typical in static analysis, over approximation of the value sets
alleviates some of the limitations but also leads to false positives.

%The goal of this work is find a more compact representation of the heaps
%and be better able to leverage constraint solvers.
%The  But any update of the heap required a rewrite on the constraint system
%or simply was not opssible to initialize and handle the aliasing possiblities.

%The goal is to leverage that

%Research in the abstract interpretation community has taken a very
%different approach to analyzing heap manipulating programs which
%computes a summary of possible heaps.  These techniques start with an
%initial heap configuration and then using a static analysis, make
%updates to the heap following program semantics, ultimately creating
%a heap summary which represents the potential heaps resulting from
%program execution~\cite{Dillig:2011}. Because these techniques are
%based on a static analysis, the heap summaries over-approximate the
%set of feasible heap configurations.

%The primary challenge relative to heap analysis for these techniques
%is to resolve potential dependencies of local results on the global
%aliases in the heap.  Recent work addresses these issues through
%strong updates to heap locations at call sites~\cite{Dillig} and
%computation of dangerous aliases~\cite{Matosevic}. Because these
%techniques are based on a static analysis, the resulting summaries
%over-approximate the actual potential heaps.

The solution presented in this paper to enabling value sets in symbolic execution
with lazy initialization is to represent the heap as a bipartite graph
consisting of references and locations. A reference is able to point
to several different locations: each edge predicated on constraints
over aliasing between references. Locations point back to references
on different fields. The bipartite graph enables (i) the use of
aliasing to define objects rather than recursive definitions; (ii)
value set computation using only local information; and (iii) heap
updates that only impact affected locations, require no constraint
rewriting, and require no auxiliary variables in the constraints.  We
call this new heap a summary heap.

To mitigate state space explosion in GSE, the solution described in
paper uses a summary heap in the symbolic execution. This summary heap
algorithm defines how the bipartite graph updates in lazy
initialization. Unlike GSE, however, the summary heap algorithm
partitions only at points of divergence in the control flow
graph. These points of non-determinism are at field accesses or writes
that lead to null-pointer exceptions and at comparisons of
references. The former represents a divergence due to exceptional
control flow while the later due to program structure.

%In this work, we present a novel heap initialization and analysis
%technique which takes inspiration from both GSE and existing heap
%summarization techniques. The intuition behind our analysis is to
%construct the heap lazily during symbolic execution but reduce the
%points of non-determinism in the symbolic execution tree by analyzing
%each control-flow path only once for any given set of isomorphic
%heaps. To represent the exact set of feasible concrete heap
%structures resulting from execution of the control-flow path, we use
%a heap summary.

Importantly, the summary heap algorithm is sound and complete with
respect to properties that are provable using GSE. This proof is
accomplished by showing the existence of a bisimulation relation
between states in GSE and states in the summary heap algorithm. In
practical terms, any property that can be proved using GSE can also be
proved using summary heaps, furthermore, any property proved by
summary heaps can also be proved by GSE. Of course, Both require a bound on heap
reference chains and loops.

Aside from the novelty of the heap summary and its application to
symbolic execution, the new data structure appears to ameliorate state
explosion in symbolic execution as hoped. A preliminary implementation in Java
Pathfinder (JPF), described in this paper, compares the heap summary
algorithm on a handful of benchmarks, each representing different
degrees of initialization and branching, to GSE with lazy
initialization in Symbolic Pathfinder (SPF) and implementation
lazier\# also in SPF. The results show that in general, that the heap
summary algorithm improves over other techniques, and in some
instances, the improvement is remarkable: two-orders of magnitude
reduction in running time. More critically though, the heap summary
enables the initialization of larger more complex heaps than
heretofore possible as shown in our results.

\begin{comment}
We implement the summary heap algorithm as an extension to \emph{Java
  PathFinder} (JPF) and compare it to GSE with lazy initialization in
\emph{Symbolic Pathfinder (SPF)} and an implementation of lazier\#
initialization in SPF.  The comparison shows on some examples up to a two-order of magnitude
reduction in the total time taken to explore the same state space
defined by the bound on the longest heap reference chain.  For these
examples, we show that where other GSE approaches are unable to
complete exploration within the provided time bound, the summary heap
finishes exploration in a few seconds.
\end{comment}

%shows that it can improve the scalability of symbolic execution of
%heap manipulating programs X fold over GSE-based analyses while
%maintaining precision and efficiency.

%preserves the heap
%configurations and program behaviors 

%complete --> anything prove with GSE you can with heap sound -->
%preserves the same behaviors in the GSE machine.

%Our analysis improves on existing GSE approaches by reducing
%the size of the symbolic execution state space explored, thereby
%improving scalability of symboic execution for heap manipulating
%software. It improves on existing heap summarization techniques by
%enabling analysis of arbitrary recursive data structures (no initial
%heap configuration is required) while avoiding the imprecision
%introduced by these techniques.

%\nsr{a paragraph that provides a breif summary of the results.. would
%  be nice if we have numbers for lazier and lazier Sharp as well.}


\noindent{This paper makes the following contributions:}

\begin{compactdesc}

\item\textbf{-} A summary heap as a bipartite graph that supports aliasing, local value set computation, and heap updates.

% to handle alias and efficient updates of constraints.

\item\textbf{-} A summary heap algorithm to initialize, summarize, and
  update the bipartiate graphs during symbolic execution.

\item\textbf{-} A proof of the existence of a bisimulation relation to establish
  that the heap summary approach is sound and complete with respect to
  properties provable by GSE.

\item\textbf{-} A proof of concept implementation and small empirical study to demonstrate the scability of the heap summary approach
  compared to other GSE approaches.

\end{compactdesc}
The rest of this paper defines summary heap and its to symbolic
execution. Following the algorithm definition, the existence proof of
bisimulation is given with the accompanying corollaries for soundness
and completeness. This is followed by the implementation in JPF and
the evaluation. The paper ends with the conclusion and future work.


%\item{We present a novel inter-procedural analysis technique for 
%symbolic execution of heap manipulating software which constructs 
%a precise heap summary.}
%\item{We use the JavaLite language~\cite{saints-MS} to formalize 
%the algorithm for constructing and manipulating the heap summary
%on-the-fly during symbolic execution.}
%\item{We implement our approach in the Symbolic PathFinder tool and
%empirically demonstrate that our technique improves
%the scalability of symbolic execution of heap maninpulating software
%over GSE, while maintaining efficiency and precision.}
%\item{We prove that at any given point during symbolic execution, the symbolic 
%heap represents the exact set of feasible concrete heap structures 
%for the program under analysis.}
% \end{description}

%\nsr{needs
%  some text on the fact we use java lite to formalize the heap
%  summary, some key characteristicss of the heap such as the fact it
%  is a bipartiate graph with locations and referneces, properties of
%  the heap such as the determinism and immutability}

%\nsr{Is any part of the formalism borrowed
%from the dilligs? Which part are unique?}  \nsr{end on a couple
%sentences about the various rules that will be talked about in the
%paper}

%\nsr{The reader should be convinced about our expressiveness
%  claim here}

%\nsr{a paragraph that provides intution on how we are a bisumulation
%  with the GSE..reader should be convinced about the precision claim}

\begin{comment}
\newcommand{\Indstate}[1][1]{\State\hspace{#1\algorithmicindent}}

\begin{figure}
\begin{center}
\begin{algorithmic}[1]
\Procedure{load}{$r,f$}
\If{$r$ is initialized and $f$ is uninitialized}
\If{ $f$ has a reference type}
\State nondeterministically assign to $f$:
\State  \ \ null  %hacky way to indent.
\State \ \ non-null
\EndIf
\If{$f$ has a primitive type}
\State assign $f$ a new symbol
\EndIf
\EndIf
\If{$r$ is uninitialized}
\State nondeterministically assign to $f$:
\State  \ \ a new symbolic location  %hacky way to indent.
\State \ \ an existing symbolic location
\EndIf
\State\Return $r.f$
\EndProcedure
\end{algorithmic}
\end{center}
\caption{Lazier\# Initialization}
\end{figure}

Lazy initialization is a symbolic execution technique where memory structures are created on-demand, as they are required.
\end{comment}



