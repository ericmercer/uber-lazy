

\section{Evaluation}
\label{sec:eval}
In this section we evaluate the effectiveness of the \symtxt{}
approach at analyzing programs with unbounded complex data input in
the context of symbolic execution. In order to perform our evaluation
we implement the \symtxt{} technique and evaluate its efficiacy on
three Java data structure artifacts. We compare the results of the
\symtxt{} approach with other state of the art techniques that
initialize complex data input symbolically. 

Symbolic Pathfinder
(SPF)~\cite{visser:ase03,Pasareanu:ISSTA08,pasareanu:ase10,DBLP:journals/ase/PasareanuVBGMR13}. SPF
is an open source engine for performing symbolic execution on Java
bytecode. SPF overwrites the concrete execution semantics of Java
bytecode to generate a symbolic execution tree. SPF contains an
implementation for GSE with lazy initialization. Recent work also
provides implementations of the lazier and lazier\# algorithms in the
SPF framework~\cite{Hillery:2014}.

%since state matching in general is undecidable.  SPF leverages this
%to define symbolic execution semantics for Java bytecode.  At
%bytecodes that access uninitialized symbolic fields it creates custom
%non-deterministic choices for the field to be null, new instance of
%its type, and aliases to any previously initialized symbolic
%fields~\cite{} SPF performs a stateless search to generate the
%symbolic execution tree.

We create a new extension to SPF in order to implement the~\symtxt{}
approach. In addition to the operations presented in the Javalite
semantics, the implementation contains support for operations over
integers. Examples of bytecode that we overwrite in the SPF engine are
as follows: (i) field access bytecodes, e.g., GETFIELD and ALOAD
bytecodes, to implement the field-access and summarize rules
in~\figref{fig:symInit} and~\figref{fig:fHeap}(a), (ii) the field
write bytecodes, e.g., PUTFIELD and ASTORE bytecodes, to implement the
field-write rules in~\figref{fig:fHeap}(a), (iii) checking equality of
references bytecode, IF\_ACMPEQ and IF\_ACMPNE, to implement the
equals references-true and references-false rules in~\figref{fig:eqs}
(iv) linear arithmetic operations on integers, and (v) comparison
operations on integers. We are currently working on adding support for
floating point operations, arrays, and bit-operations.  We use the
\texttt{jConstraints} library that provides support to handle the heap
constraints~\cite{ase2014-ghilrr,jpf2014-dghirr}. It uses the z3
solver,~\cite{z3}, as the backend to solve the constraints. We
leverage the incremental solving feature in z3 in our experiments. We
also implement other optimizations that cache and re-use solutions to
previous constraints. These optimizations are an important part of our
implementation because only small portions of the heap constraint
changes from one state to another.


%The default constraints library in SPF requires constraints to be in
%the CNF form, and is unable to support constraints generated by the
%\symtxt{} approach since they contain disjunctions. Transforming the
%constraints generated by the \symtxt{} approach into a CNF form
%proved to be inefficient.

\begin{comment}
Loops and recursive methods over symbolic variables are bounded based
on some user-provided limit. These bounds are based on some
control-flow structure of the program and are often insufficient for
analyzing programs with input of complex data types as demonstrated
in~\cite{Kiasan07,Deng:2006}. In this work we use the $k$-bounding
technique that bounds the length of a reference chain from the root of
the heap~\cite{Deng:2006}.\nsr{check this!} Note we use $k$-bounding
because it preserves the functional equivalence of \gsetxt{}, lazier,
lazier\# and \symtxt{} techniques, a fact which can be established by
induction over the length of reference chains from a given initial
state. The $n$-bounding approach restricts the total number of
references created along a certain path. There is no easy way to
compare the number of references generated by \symtxt{} and other
techniques since \symtxt{} can create many references at a single
access point in its heap summary.
\end{comment}


\subsection{Case-Study} 

The goal of our technique to evaluate the efficiacy of our approach
with respect to other state of the art algorithms for symbolic
execution for dealing for unbounded complex data input. We empirically
evaluate \symtxt{} by considering the following research question:

\begin{description}
\item {\bf RQ1:} How does the cost of using \symtxt{} compare to that
  of \gsetxt{}, lazier, and lazier\# algorithms?

%\item {\bf RQ2:} Does \symtxt{} technique enable other back-end
%  approaches that can leverage its output?
\end{description}

To evaluate we use three Java data structure artifacts (a) Linked List
(b) Binary Search Tree, and (c) Tree Map. These data structures
programs are often used to the evaluate symbolic execution algorithms
with arbitrary heap inputs. The \emph{independent} variable in our
study is the algorithm for initializing symbolic references and the
$k$-bound. The initialization algorithms that we vary in our study
are: \symtxt{}, \gsetxt{}, lazier, and lazier\#. We also vary the
$k$-bound for each the algorithms. Note that $k$-bounding bounds the
length of a reference chain from the root of the heap~\cite{Deng:2006}
We select three dependent variables and measures for our study: (i)
time, (ii) states explored, and (iii) paths generated. The \emph{time}
is the total time taken by each algorithm to explore the symbolic
execution tree as well as total constraint solving time. The
\emph{states explored} represents the number of nodes in the symbolic
execution tree while the \emph{paths generated} represent as the name
suggests the number of unique paths in the symbolic execution tree.


\begin{comment}
\symtxt{} creates fewer execution paths than \gsetxt{}, but it does so
with increased path constraint complexity. Determining the impact of
this tradeoff in real-world applications is an important research
question.

Since the number of paths in \gsetxt{} is exponential in the number of
lazy initializations, it is expected that programs for which the
number of lazy initializations is proportional to program complexity
will evaluate more quickly using \symtxt{}. On the other hand, since
\symtxt{} places a greater burden on the constraint solver, it is
expected that programs where the lazy initialization count is constant
or slowly increasing with respect to program complexity will evaluate
more quickly using \symtxt{}.

\subsection{Implementation}

The Java Pathfinder (JPF) symbolic execution engine contains an
implementation of \gsetxt{}, which we extended with our own
implementation of \symtxt{}. Our heap representation lends itself to a
number of simple performance optimizations, which have been included
in the implementation. First, solutions to previous constraint
problems are cached and re-used, to avoid sending a large number of
queries to the SMT solver. Second, because only small portions of the
path condition change from one state to the next, incremental solving
is enabled to provide a substantial performance increase. Finally, by
examining the location sets involved in a reference compare operation,
a large number of reference compare instructions may be dispatched
without consulting the solver to begin with.

For practical purposes, the implementation also includes a number of
features not shown in the simple language described in section 2. For
example, integer operations are required in order to reason about
ordered data structures such as binary search trees and red/black
trees. The description of these operations is outside the scope of
this paper.

\subsection{Bounding}
In order to perform a practical evaluation of programs involving
recursive data structures, it is generally necessary to impose some
sort of bounding to reduce the number of lazy initializations to a
manageable level. While these bounds may be asserted as invariants
within the program in-situ, it is more practical to apply bounding via
external means. There are several bounding techniques that may be
applied to both \gsetxt{} and \symtxt{}, including execution path
length bounding, k-bounding and n-bounding. k-bounding and n-bounding
both operate by imposing limits on the size of the symbolic input
heap, but differ in how such bounds are defined. n-bounding limits the
number of objects created by lazy initialization, while k-bounding
limits the length of initialized reference chains. k-bounding has the
property of exhaustively exploring the full breadth of a given data
structure, while n-bounding tends to explore deeper heap shapes while
being somewhat less thorough in breadth. In addition, k-bounding and
n-bounding may be combined to adjust the desired level of
approximation between depth and breadth.

While k-bounding and n-bounding are applicable to both \gsetxt{} and
\symtxt{}, they are not both equally suited for comparing the two
methods. The main reason for this lies in how how each bounding
technique impacts the functional equivalence of the respective
methods.  k-bounding preserves the functional equivalence of \gsetxt{}
and \symtxt{}, a fact which can be established by induction over the
length of reference chains from a given initial state. In contrast,
\gsetxt{} and \symtxt{} are not generally functionally equivalent
under n-bounding. The reason is that since a \symtxt{} state must
represent all possible \gsetxt{} states on an execution path, it
generally includes more locations than any single \gsetxt{} state it
represents. This difference in state counts makes it difficult to
externally assert n-bounding in a manner that preserves functional
equivalence between \gsetxt{} and \symtxt{}. Functional equivalence
may be preserved in the case where n-bounds are asserted via in-situ
invariants, but the significant increase in constraint complexity
makes this approach impractical. For this reason, n-bounding is was
not selected for comparing \gsetxt{} to \symtxt{} in the tests
performed in this paper.

In contrast to the heap-based bounds provided by k-bounding and
n-bounding, execution path-length bounding works by limiting the
number along any given execution path. As with other bounding
techniques, the usefulness of path-length bounding hinges on whether
it preserves functional equivalence. While path-length bounding
preserves functional equivalence for \gsetxt{} and \symtxt{} as
formulated in this paper, it does not preserve it for the algorithms
as they are implemented in JPF. The reason for the discrepancy lies in
how states are defined in JPF. In JPF, the notion of states is closely
tied to the concept of nondeterminism. New states are created in JPF
only when a nondeterministic choice is made, meaning the number of
states on an execution path is tied to the number of nondeterministic
choices. A discrepancy in the length of the respective execution paths
may be caused by any difference in nondeterminism between the two
methods. This is significant, since the nondeterminism in \symtxt{}
and \gsetxt{} differs in both field reads and in reference
compares. Field reads in \symtxt{} are deterministic, whereas in
\gsetxt{} they may initiate a nondeterministic lazy
initialization. Conversely, in \gsetxt{} address compares are
deterministic, but in \symtxt{} address compares require a
nondeterministic assertion over the truth of the branch condition. For
this reason, path-length bounding was not used for this experimental
evaluation. For future tests, we are considering inserting artificial
points of nondeterminism in order to establish functional equivalence
of path-length bounds between \gsetxt{} and \symtxt{}.

\subsection{Evaluation} 


Experimental set-up: TO BE ADDED

Test Cases

In order to evaluate the performance of \symtxt{}, the implementation
was tested against three examples: LinkedList, BinarySearchTree,
TreeMap.  The LinkedList example tests performance on linked list data
structures. The test program begins by assuming an object invariant
before initiating a sequence of contains() method calls. This is a
challenging example for \gsetxt{} because each call to the contains()
method contains a new lazy initialization, which in turn creates an
exponential path expansion throughout program execution. While the
constraints for each path are easily solved, the sheer number of paths
quickly becomes overwhelming.

The BinarySearchTree example test program consists simply of asserting
the object invariant for a binary search tree. This example is
interesting because it demonstrates nondeterminism from both aliasing
constraints created during lazy initialization, and linear constraints
from evaluating conditionals over numeric symbols.

Like the BinarySearchTree test, the TreeMap test is simply an
assertion of an object invariant, in this case for a red/black
tree. This example serves as a stress test for \symtxt{}, since most
of the nondeterminism comes from linear constraints over the shape of
the tree, rather than aliasing constraints created during lazy
initialization. In this case, the path advantage for \symtxt{} is
minimized.

For all tests, program complexity was adjusted via k-bounding. For the
LinkedList test, the number of contains() method calls was added as an
additional parameter. After the conclusion of each test, the test
run-time, state count, and path counts were recorded.

The results of the experiments are shown in table \ref{tab:results}.

\end{comment}
